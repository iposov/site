# N-грамм модели языка

Модель языка. Функция, которая каждому предложения языка сопоставляет число. «Вероятность предложения». Например, представим, что мы берем из всех книг на русском случайное одно предложение. Или из всех фраз, сказанных носителями языка.
"Я сплю" - большая вероятность
"Я спать" - поменьше
"Я спали" - почти нулевая

Важные условия. Каждое число должно быть неотрицательным. Сумма «вероятностей» по всем предложениям должна быть ровно 1.

Модели могут быть очень разные.
N-грамм модель. Сопоставляют вероятность предложению на основе вероятностей появления групп из N-слов (n-грамм)
Вырожденная модель: "Я сплю" - 0.5 "Я ем" - 0.5, все остальные предложения вероятность 0.
Нейросетевые модели, условно.

Вспоминаем теорию вероятностей.
Вспомним, что такое условная вероятность.
Кидаем кубик, события, что выпали {1, 2, 3, 4, 5, 6}, вероятность каждого события 1/6.
(это мы задали вероятностное пространство, т.е. все, что может случиться, и какие у этого вероятности).
P{выпало четное} = P{2 или 4 или 6} = 1/6 + 1/6 + 1/6 = 3 / 6 = 1/2.
P{выпало четное} = 3 подходящих варианта / 6 вариантов всего = 3/6 = 1/2
P{выпало простое} = 3 подходящих варианта (2, 3, 5) / 6 вариантов всего = 3/6 = 1/2

независимость
A = выпало четное
B = выпало простое
P{A и B} = 1 подходящий вариант (выпало 2) / 6 вариантов всего = 1/6
P{A} = 1 / 2 см. выше
P{B} = 1 / 2

Проверим независимость событий A и B: у независимых событий P{A и B} = P{A} * P{B}
У нас 1/6 != 1/2*1/2
Значит, события A и B не независимы.

С = выпало число, меньшее 3
P{C} = 2 подходящий вариант (выпало 1, 2) / 6 = 2 / 6 = 1/3

P{A и C} = четное < 3, 1 подходящий вариант (выпало 2) / 6 вариантов всего = 1/6
P{A} = 1/2
P{C} = 1/3
1/6 = P{A и С} = P{A} * P{C} = 1/6

Итого, события A и C независимы (выпало ли четное не зависит от того, выпало ли число, меньшее трех).

## Про условную вероятность

P{A | B} - условная вероятность события A при условии события B.
P{A | B} = P{A и B} / P{B}
P{четное} = 1/2
P{четное | простое} = P{четное и простое} / P{простое} = 1/6  /  3/6 = 1/3.

P{четное | выпало не 1} = P{четное, но не 1} / P{выпало не 1} = 3/6  /  5/6 = 3/5 > 1/2

## n-грамм модель

Как будто идет процесс генерации случайных слов (СЛОВ + Маркер конца предложения), причем каждое следующее слово зависит только от (n-1) предыдущего.

P{w1 w2 w3 ... wk} - с какой вероятностью сгенерировано предложение из слов w1 w2 ... wk. P{я сплю} = ? Предложение из k слов

                         P{A | B} = P{A и B} / P{B}  <=> P{A и B} = P{A | B} * P{B}

P{w1 w2 w3 ... wk} = P{wk | w1 w2 w3 ... w{k-1}} * P{w1 w2 w3 ... w{k-1}} =
    пользуемся предположением n-грамм модели. Давайте для определенности n=3
= P{wk | w{k-1}, w{k-2}} * P{w1 w2 w3 ... w{k-1}}
    аналогично
= P{wk | w{k-1}, w{k-2}} * P{w{k-1} | w{k-2}, w{k-3}} * P{w1 w2 w3 ... w{k-2}}
= ...
= ...
= P{wk | w{k-1}, w{k-2}} *
  P{w{k-1} | w{k-2}, w{k-3}} *
  P{w{k-2} | w{k-3}, w{k-4}} *
  ...
  P{w{1} | w{0}, w{-1}} *                // w{0} и w{-1} это маркеры конца предложения

 Например P{Пара уже скоро закончится} =
 для n = 3
 P{закончится | уже скоро} * P{скоро | пара уже} * P{уже | * пара} * P{пара | * *}
 для n = 2
 P{закончится | скоро} * P{скоро | уже} * P{уже | пара} * P{пара | *}
 для n = 1
 P{закончится} * P{скоро} * P{уже} * P{пара}
